# --- Importaciones ---
import requests
import json
from .config import URL_GETONBRD, MAX_VACANTES_POR_PALABRA
from .utils import fecha_actual, calc_prioridad
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
# --- Fin Importaciones ---

# --- Constante de L√≠mite ---
LIMITE_ANTIGUEDAD_DIAS = 60 # M√°ximo 2 meses

def _procesar_resultados_getonbrd(json_data: list, keyword: str):
    """
    Analiza la respuesta JSON de GetOnBrd, aplica el filtro de antig√ºedad, 
    y extrae las vacantes con el mapeo corregido.
    """
    vacantes_procesadas = []
    
    # 1. CALCULAR FECHA L√çMITE
    fecha_limite = datetime.now() - timedelta(days=LIMITE_ANTIGUEDAD_DIAS)
    
    for item in json_data[:MAX_VACANTES_POR_PALABRA]: 
  
        # üí° Acceso a secciones principales del JSON
        attributes = item.get("attributes", {})
        links = item.get("links", {})
        timestamp_publicacion = attributes.get("published_at")

        # ‚ö†Ô∏è FILTRO DE ANTIG√úEDAD (Si es demasiado viejo, lo saltamos)
        if timestamp_publicacion:
            fecha_publicacion = datetime.fromtimestamp(timestamp_publicacion)
            
            if fecha_publicacion < fecha_limite:
                continue # Omitir y pasar a la siguiente vacante
        # üí° L√ìGICA DE EXTRACCI√ìN (Usando 'expand')
        
        # 1. EMPRESA
        company_data = attributes.get("company", {}).get("data", {})
        if company_data:
             empresa_candidata = company_data.get("attributes", {}).get("name", "No indicado")
        else:
             # Fallback al ID si falla la expansi√≥n
             parts = item_id.split('-')
             empresa_candidata = parts[-3] if len(parts) >= 3 else "No indicado"

        # 2. UBICACI√ìN
        cities_data = attributes.get("location_cities", {}).get("data", [])
        regions_data = attributes.get("location_regions", {}).get("data", [])
        
        ubicacion_str = "No indicado"
        if cities_data:
            nombres_ciudades = [c.get("attributes", {}).get("name") for c in cities_data]
            nombres_ciudades = [n for n in nombres_ciudades if n] 
            ubicacion_str = ", ".join(nombres_ciudades) if nombres_ciudades else "No indicado"
        elif regions_data:
            nombres_regiones = [r.get("attributes", {}).get("name") for r in regions_data]
            nombres_regiones = [n for n in nombres_regiones if n] 
            ubicacion_str = ", ".join(nombres_regiones) if nombres_regiones else "No indicado"
        else:
            ubicacion_str = "Remoto" if attributes.get("remote") else "No indicado"

        # 3. NIVEL (Seniority)
        seniority_data = attributes.get("seniority", {}).get("data", {})
        if seniority_data:
            nivel_str = seniority_data.get("attributes", {}).get("name", "No indicado")
        else:
            nivel_str = "No indicado"
         # --- 3. CORRECCI√ìN DE FECHA DE PUBLICACI√ìN Y DESCRIPCI√ìN ---
        
        # Fecha de Publicaci√≥n: Se env√≠a como un timestamp Unix (n√∫mero grande).
        timestamp_publicacion = attributes.get("published_at")
        
        # Descripci√≥n: Contiene etiquetas HTML que deben eliminarse.
        descripcion_html = attributes.get("description", "")
        descripcion_limpia = BeautifulSoup(descripcion_html, 'html.parser').get_text(separator=' ', strip=True)

        # Salario: Mapeo de m√≠nimo y m√°ximo a una sola cadena
        min_salary = attributes.get("min_salary")
        max_salary = attributes.get("max_salary")
        salario_str = f"${min_salary} - ${max_salary}" if min_salary or max_salary else "No informado"

        vacante_dict = {
            # --- CAMPOS F√ÅCILES Y CR√çTICOS ---
            "titulo": attributes.get("title", "No indicado"), 
            "url": links.get("public_url", ""), 
            "descripcion": descripcion_limpia,
            
            # --- DATOS CRUDOS ADICIONALES ---
            "fecha_publicacion": fecha_publicacion.strftime("%Y-%m-%d"), # ‚úÖ FECHA FORMATEADA
            
            # --- CAMPOS QUE LA IA DEBE LLENAR (VAC√çOS POR DEFECTO) ---
            "empresa": empresa_candidata, # ‚úÖ CAMPO MAPEADO
            "ubicacion": ubicacion_str,   # ‚úÖ CAMPO MAPEADO
            "modalidad": "Remoto" if attributes.get("remote") else "Presencial", # ‚úÖ CAMPO MAPEADO
            "nivel": nivel_str,           # ‚úÖ CAMPO MAPEADO
            "jornada": attributes.get("modality", {}).get("data", {}).get("attributes", {}).get("name", "No indicado"), # ‚úÖ JORNADA REAL (Full time, etc.)
            "salario": salario_str,       # ‚úÖ CAMPO MAPEADO
            
            # --- CAMPOS AUXILIARES ---
            "fecha_busqueda": fecha_actual(),
            "prioridad": calc_prioridad(attributes.get("remote")), # ‚úÖ PRIORIDAD CALCULADA
            "keyword_buscada": keyword
        }
        
        vacantes_procesadas.append(vacante_dict)
        
    return vacantes_procesadas

# ‚ö†Ô∏è Funci√≥n principal (debe recibir el argumento 'keyword')
def buscar_vacantes_getonbrd(keyword: str): 
    """Realiza la solicitud API a GetOnBrd para una √∫nica palabra clave."""
    
    vacantes_raw = []
    url = URL_GETONBRD.format(requests.utils.quote(keyword)) # Codificar keyword para la URL
    
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        #print(json.dumps(data['data'][0], indent=2))
        
        if 'data' in data and isinstance(data['data'], list):
            vacantes_raw.extend(
                _procesar_resultados_getonbrd(data['data'], keyword)
            )
            
    except requests.exceptions.RequestException as e:
        # Lanza una excepci√≥n para que sea capturada por el ThreadPoolExecutor
        raise Exception(f"Error HTTP en GetOnBrd para '{keyword}': {e}") 
        
    return vacantes_raw